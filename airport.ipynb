{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOf+7pXFuL1ttJDJRVcL0wC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ypeng12/Airline/blob/main/airport.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yellowstone\n",
        "\n",
        "* Website - https://yellowstoneairport.mdt.mt.gov/flights.aspx\n",
        "\n",
        "\n",
        "\n",
        "in this web could get the data from May to Oct during a year.\n",
        "\n",
        "\n",
        "*  The yellowstone airport is open at May and close at Deceber ( from the online we could find this time is not exact same as the yellowstone close)\n",
        "*   The most of the airport is Saturday\n",
        "\n",
        "\n",
        "The code for the yellowstone\n",
        "\n",
        "\n",
        "*   copy from the website the data directly to the code\n",
        "*   make csv file and write data into it\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EX4QTS_PovRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the raw data\n",
        "raw_data = \"\"\"Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 06\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 07\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 08\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 09\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 10\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 11\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 12\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 13\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 14\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 15\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 16\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 17\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 18\n",
        "Delta\t4314\tSLC\t1:15 PM\t2:32 PM\tMay 19\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 20\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 20\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 21\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 22\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 23\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 23\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 24\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 24\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 25\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 25\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 26\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 26\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 27\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 27\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 28\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 29\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 30\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 30\n",
        "Delta\t4314\tSLC\t11:45 AM\t1:00 PM\tMay 31\n",
        "Delta\t4313\tSLC\t3:30 PM\t4:40 PM\tMay 31\"\"\"\n",
        "\n",
        "# Process the raw data\n",
        "lines = raw_data.split('\\n')\n",
        "data = []\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    airline = parts[0]\n",
        "    flight_number = parts[1]\n",
        "    destination = parts[2]\n",
        "    departure_time = ' '.join(parts[3:5])\n",
        "    arrival_time = ' '.join(parts[5:7])\n",
        "    date = ' '.join(parts[7:])\n",
        "    data.append([airline, flight_number, destination, departure_time, arrival_time, date])\n",
        "\n",
        "# Define column names\n",
        "columns = ['Airline', 'Flight Number', 'Destination', 'Departure Time', 'Arrival Time', 'Date']\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/YellowStone/Departure')\n",
        "\n",
        "# Create the Downloads directory if it doesn't exist\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file\n",
        "csv_file = os.path.join(downloads_directory, 'Yellow-May-24.csv')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(csv_file, index=False)\n",
        "\n",
        "print(f\"Data has been written to {csv_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Cr-CIR_cpP",
        "outputId": "978528cc-e212-4d06-f0cd-d34cf6b19650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been written to /root/YellowStone/Departure/Yellow-May-24.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code want to add the week of the day ( not finished)"
      ],
      "metadata": {
        "id": "DZyzaP4it6Os"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for the Hawai Airport\n",
        "\n",
        "This code performs the following steps:\n",
        "\n",
        "- Requests the webpage content.\n",
        "- Parses the HTML using BeautifulSoup.\n",
        "- Locates the departure table section.\n",
        "- Extracts flight data from each row in the table.\n",
        "- Stores the data in a Pandas DataFrame.\n",
        "- Saves the DataFrame as a CSV file in the Downloads directory."
      ],
      "metadata": {
        "id": "fHlHXpF2swNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Daniel\n",
        "*   Ellison\n",
        "*   Lihue\n",
        "*   Kahului\n",
        "*   Hilo\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uvgJucVo37L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "sgBKc6kN1O4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Define the raw data\n",
        "raw_data = \"\"\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Split the data into lines\n",
        "lines = raw_data.split('\\n')\n",
        "data = []\n",
        "\n",
        "# Initialize variables for processing\n",
        "airline = airline_code = flight = to = sched = updated = None\n",
        "status_keywords = {\"In\", \"Arrived\", \"Scheduled\", \"Delayed\", \"Landed\", \"No\", \"Departed\",\"Cancelled\"}\n",
        "\n",
        "def is_flight_number(s, airline_code):\n",
        "    return s.startswith(airline_code) and any(char.isdigit() for char in s)\n",
        "\n",
        "def extract_to_and_status(parts):\n",
        "    combined = ' '.join(parts)\n",
        "    for keyword in status_keywords:\n",
        "        if keyword in combined:\n",
        "            to_part, status_part = combined.split(keyword, 1)\n",
        "            return to_part.strip(), keyword, status_part.strip()\n",
        "    return combined, \"\", \"\"\n",
        "\n",
        "def extract_times(remaining):\n",
        "    time_pattern = r'\\d{1,2}:\\d{2} [AP]M'\n",
        "    times = re.findall(time_pattern, remaining)\n",
        "    return times\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    parts = line.split()\n",
        "\n",
        "    if not parts:\n",
        "        continue  # Skip empty lines\n",
        "\n",
        "    # Determine if the current line could be an airline line\n",
        "    if i + 1 < len(lines) and parts and lines[i + 1].split() and is_flight_number(lines[i + 1].split()[0], parts[0]):\n",
        "        # Airline name and code from the first part of the current line\n",
        "        airline = line\n",
        "        airline_code = parts[0]\n",
        "\n",
        "    elif airline_code and parts and is_flight_number(parts[0], airline_code):\n",
        "        # Flight number\n",
        "        flight = parts[0]\n",
        "    else:\n",
        "        # Extract To and Status\n",
        "        to, status, remaining = extract_to_and_status(parts)\n",
        "\n",
        "        # Ensure 'To' contains a comma\n",
        "        if ',' not in to:\n",
        "            continue\n",
        "\n",
        "        # Identify schedule and updated times\n",
        "        times = extract_times(remaining)\n",
        "\n",
        "        if len(times) >= 2:\n",
        "            sched = times[0]\n",
        "            updated = times[1]\n",
        "        elif len(times) == 1:\n",
        "            sched = times[0]\n",
        "            updated = \"\"\n",
        "\n",
        "        # Add row to data\n",
        "        data.append([airline_code, flight, to, sched, updated])\n",
        "        # Reset variables for next entry\n",
        "        flight = to = sched = updated = None\n",
        "\n",
        "# Define column names\n",
        "columns = ['Airline', 'Flight', 'To', 'Sched.', 'Updated']\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/Hawaii')\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file and Excel file\n",
        "csv_file = os.path.join(downloads_directory, 'Hilo_0704_2024.csv')\n",
        "excel_file = os.path.join(downloads_directory, 'Hilo_0704_2024.xlsx')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(csv_file, index=False)\n",
        "print(f\"Data has been written to {csv_file}\")\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "df.to_excel(excel_file, index=False)\n",
        "print(f\"Data has been written to {excel_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3pigEkKswDI",
        "outputId": "75fa2dc6-2303-4744-c36a-daf6d4059b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been written to /root/Hawaii/Hilo_0704_2024.csv\n",
            "Data has been written to /root/Hawaii/Hilo_0704_2024.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "xwDchTOU24MD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "HNL – Official State of Hawaii Website (Honolulu)\n",
        "https://airports.hawaii.gov/hnl/flights/\n",
        "- Daniel K. Inouye International Airport\n",
        "- Ellison Onizuka Kona International Airport at Keahole\n",
        "- Hilo\n",
        "- Kahului\n",
        "- Lihue\n",
        "\n"
      ],
      "metadata": {
        "id": "aXBWERQ_Hukj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Define the raw data\n",
        "raw_data = \"\"\"\n",
        "\n",
        "\n",
        "HA\tHawaiian Airlines\n",
        "HA204\n",
        "\tKE7754\n",
        "\tJL6609\n",
        "\tDL6841\n",
        "\tB65853\n",
        "Honolulu, HIIn Air11:10 AM11:07 AM\n",
        "AS\tAlaska Airlines\n",
        "AS840\n",
        "Seattle, WAIn Air11:13 AM11:06 AM10\n",
        "HA\tHawaiian Airlines\n",
        "HA234\n",
        "\tUA7874\n",
        "\tJL6607\n",
        "\tDL6848\n",
        "\tB65848\n",
        "Honolulu, HIScheduled11:45 AM\n",
        "WN\tSouthwest Airlines\n",
        "WN2355\n",
        "Honolulu, HIScheduled11:50 AM11:50 AM7\n",
        "HA\tHawaiian Airlines\n",
        "HA66\n",
        "Sacramento, CAScheduled12:00 PM\n",
        "HA\tHawaiian Airlines\n",
        "HA254\n",
        "\tUA7849\n",
        "\tJL6610\n",
        "\tDL6825\n",
        "\tB65880\n",
        "\tAA7873\n",
        "Honolulu, HIScheduled12:25 PM\n",
        "UA\tUnited Airlines\n",
        "UA1563\n",
        "\tLH8932\n",
        "\tAV2357\n",
        "San Francisco, CAScheduled12:52 PM12:52 PM8\n",
        "AS\tAlaska Airlines\n",
        "AS577\n",
        "\tAA9348\n",
        "San Jose, CAScheduled12:59 PM12:59 PM10\n",
        "HA\tHawaiian Airlines\n",
        "HA264\n",
        "\tJL6612\n",
        "\tDL6851\n",
        "\tB65888\n",
        "\tAA7870\n",
        "Honolulu, HIScheduled1:03 PM\n",
        "HA\tHawaiian Airlines\n",
        "HA68\n",
        "Oakland, CAScheduled1:05 PM\n",
        "UA\tUnited Airlines\n",
        "UA466\n",
        "\tAV2258\n",
        "\tAC3502\n",
        "Los Angeles, CAScheduled1:09 PM1:09 PM9\n",
        "HA\tHawaiian Airlines\n",
        "HA64\n",
        "Los Angeles, CAScheduled1:35 PM\n",
        "AA\tAmerican Airlines\n",
        "AA266\n",
        "Los Angeles, CAScheduled1:42 PM1:42 PM6\n",
        "HA\tHawaiian Airlines\n",
        "HA274\n",
        "\tJL6613\n",
        "\tDL6852\n",
        "Honolulu, HIScheduled1:59 PM\n",
        " \"\"\"\n",
        "\n",
        "# Split the data into lines\n",
        "lines = raw_data.split('\\n')\n",
        "data = []\n",
        "\n",
        "# Initialize variables for processing\n",
        "airline = airline_code = flight = to = sched = updated = None\n",
        "status_keywords = {\"In\", \"Arrived\", \"Scheduled\", \"Delayed\", \"Landed\", \"No\", \"Departed\",\"Cancelled\"}\n",
        "\n",
        "def is_flight_number(s, airline_code):\n",
        "    return s.startswith(airline_code) and any(char.isdigit() for char in s)\n",
        "\n",
        "def extract_to_and_status(parts):\n",
        "    combined = ' '.join(parts)\n",
        "    for keyword in status_keywords:\n",
        "        if keyword in combined:\n",
        "            to_part, status_part = combined.split(keyword, 1)\n",
        "            return to_part.strip(), keyword, status_part.strip()\n",
        "    return combined, \"\", \"\"\n",
        "\n",
        "def extract_times(remaining):\n",
        "    time_pattern = r'\\d{1,2}:\\d{2} [AP]M'\n",
        "    times = re.findall(time_pattern, remaining)\n",
        "    converted_times = [convert_time(t) for t in times]\n",
        "    return converted_times\n",
        "\n",
        "def convert_time(time_str):\n",
        "    # Parse the time using datetime and convert to 24-hour format\n",
        "    return datetime.strptime(time_str, '%I:%M %p').strftime('%H:%M')\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    parts = line.split()\n",
        "\n",
        "    if not parts:\n",
        "        continue  # Skip empty lines\n",
        "\n",
        "    if i+1 < len(lines) and parts and lines[i+1].split() and is_flight_number(lines[i+1].split()[0], parts[0]):\n",
        "        airline = line\n",
        "        airline_code = parts[0]\n",
        "    elif airline_code and parts and is_flight_number(parts[0], airline_code):\n",
        "        flight = parts[0]\n",
        "    else:\n",
        "        to, status, remaining = extract_to_and_status(parts)\n",
        "        if ',' not in to:\n",
        "            continue\n",
        "        times = extract_times(remaining)\n",
        "        sched = times[0] if times else \"\"\n",
        "        updated = times[1] if len(times) > 1 else \"\"\n",
        "\n",
        "        data.append([airline_code, flight, to, sched, updated])\n",
        "        flight = to = sched = updated = None\n",
        "\n",
        "# Define column names\n",
        "columns = ['Airline', 'Flight', 'To', 'Sched.', 'Updated']\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/Hawaii')\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file\n",
        "csv_file = os.path.join(downloads_directory, 'Lihue_0705_2024.csv')\n",
        "excel_file = os.path.join(downloads_directory, 'Lihue_0705_2024.xlsx')\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv(csv_file, index=False)\n",
        "print(f\"Data has been written to {csv_file}\")\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "df.to_excel(excel_file, index=False)\n",
        "print(f\"Data has been written to {excel_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-kDVizHYXum",
        "outputId": "97884b9e-e036-410a-a74e-151ccdc569d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been written to /root/Hawaii/Lihue_0705_2024.csv\n",
            "Data has been written to /root/Hawaii/Lihue_0705_2024.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hk4x5A4p0Afl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.guamairport.com/passenger/flights/flight-schedule\n",
        "Guam"
      ],
      "metadata": {
        "id": "EUQHelPtOw7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Define the new raw data\n",
        "new_raw_data = \"\"\"July 6, 2024\tUnited\tUA165\tFukuoka\t06:55\t06:55\tdeparted\n",
        "July 6, 2024\tUnited\tUA200\tHonolulu\t06:55\t07:00\tdeparted\n",
        "July 6, 2024\tUnited\tUA151\tOsaka Kansai\t07:15\t07:15\tdeparted\n",
        "July 6, 2024\tUnited\tUA137\tNagoya, JP\t07:30\t07:30\ton time\n",
        "July 6, 2024\tUnited\tUA174\tSaipan\t08:00\t08:00\ton time\n",
        "July 6, 2024\tUnited\tUA840\tTokyo, JP ~ Narita\t11:25\t11:25\ton time\n",
        "July 6, 2024\tUnited\tUA196\tTokyo, JP ~ Narita\t12:15\t12:15\ton time\n",
        "July 6, 2024\tUnited\tUA864\tTokyo, JP ~ Narita\t13:05\t13:05\ton time\n",
        "July 6, 2024\tT'Way Air\tTW304\tSeoul, Korea\t15:10\t15:10\ton time\n",
        "July 6, 2024\tJin Air\tLJ914\tSeoul, Korea\t16:15\t16:15\ton time\n",
        "July 6, 2024\tJapan Airlines\tJL942\tTokyo, JP ~ Narita\t16:50\t16:50\ton time\n",
        "July 6, 2024\tUnited\tUA177\tOsaka Kansai\t16:55\t16:55\ton time\n",
        "July 6, 2024\tKorean Air\tKE422\tSeoul, Korea\t17:00\t17:00\ton time\n",
        "July 6, 2024\tUnited\tUA873\tTokyo, JP ~ Narita\t17:05\t17:05\ton time\n",
        "July 6, 2024\tUnited\tUA183\tManila, Philippines\t19:10\t19:10\ton time\n",
        "July 6, 2024\tUnited\tUA849\tHaneda\t19:10\t19:10\ton time\n",
        "July 6, 2024\tUnited\tUA176\tPohnpei\t20:25\t20:25\ton time\n",
        "July 6, 2024\tUnited\tUA185\tYap\t23:35\t23:35\ton time\n",
        "July 7, 2024\tJin Air\tLJ924\tBusan\t03:00\t03:00\ton time\n",
        "July 7, 2024\tJeju Air\t7C3105\tSeoul, Korea\t03:05\t03:05\ton time\n",
        "July 7, 2024\tPhilippine Airlines\tPR111\tManila, Philippines\t05:55\t05:55\ton time\n",
        "July 7, 2024\tUnited\tUA165\tFukuoka\t06:55\t06:55\ton time\n",
        "July 7, 2024\tUnited\tUA200\tHonolulu\t06:55\t06:55\ton time\n",
        "July 7, 2024\tUnited\tUA151\tOsaka Kansai\t07:15\t07:15\ton time\n",
        "July 7, 2024\tUnited\tUA137\tNagoya, JP\t07:30\t07:30\ton time\n",
        "July 7, 2024\tUnited\tUA174\tSaipan\t08:00\t08:00\ton time\n",
        "July 7, 2024\tUnited\tUA133\tChuuk\t09:20\t09:20\ton time\n",
        "July 7, 2024\tUnited\tUA840\tTokyo, JP ~ Narita\t11:25\t11:25\ton time\n",
        "July 7, 2024\tUnited\tUA196\tTokyo, JP ~ Narita\t12:15\t12:15\ton time\n",
        "July 7, 2024\tUnited\tUA864\tTokyo, JP ~ Narita\t13:05\t13:05\ton time\n",
        "July 7, 2024\tT'Way Air\tTW304\tSeoul, Korea\t15:10\t15:10\ton time\n",
        "July 7, 2024\tJin Air\tLJ914\tSeoul, Korea\t16:15\t16:15\ton time\n",
        "July 7, 2024\tJapan Airlines\tJL942\tTokyo, JP ~ Narita\t16:50\t16:50\ton time\n",
        "July 7, 2024\tKorean Air\tKE422\tSeoul, Korea\t17:00\t17:00\ton time\n",
        "July 7, 2024\tUnited\tUA873\tTokyo, JP ~ Narita\t17:05\t17:05\ton time\n",
        "July 7, 2024\tUnited\tUA183\tManila, Philippines\t19:10\t19:10\ton time\n",
        "July 7, 2024\tUnited\tUA849\tHaneda\t19:10\t19:10\ton time\n",
        "July 7, 2024\tUnited\tUA157\tKoror\t23:45\t23:45\ton time\"\"\"\n",
        "\n",
        "# Split the new data into lines\n",
        "lines = new_raw_data.split('\\n')\n",
        "data = []\n",
        "\n",
        "def find_flight_number(parts):\n",
        "    for i, part in enumerate(parts):\n",
        "        if re.match(r'[A-Za-z]+\\d+', part):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "# Function to find the first time format (XX:XX) from the back of the list\n",
        "def find_times_from_back(parts):\n",
        "    times = [part for part in parts if re.match(r'^\\d{1,2}:\\d{2}$', part)]\n",
        "    if len(times) >= 2:\n",
        "        return times[-2], times[-1]\n",
        "    return None, None\n",
        "\n",
        "# Extract data from each line\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "\n",
        "    # Extract the date\n",
        "    date_parts = []\n",
        "    for i, part in enumerate(parts):\n",
        "        date_parts.append(part)\n",
        "        if part == \"2024\":\n",
        "            date = ' '.join(date_parts)\n",
        "            break\n",
        "\n",
        "    # Find the index of the flight number\n",
        "    flight_no_index = find_flight_number(parts)\n",
        "    if flight_no_index == -1:\n",
        "        continue\n",
        "\n",
        "    flight_no = parts[flight_no_index]\n",
        "\n",
        "    # Find departure and estimated times\n",
        "    departure_time, estimated_time = find_times_from_back(parts)\n",
        "\n",
        "    if departure_time is None or estimated_time is None:\n",
        "        continue\n",
        "\n",
        "    # The TO part is between flight number and departure time\n",
        "    to_end_index = parts.index(departure_time)\n",
        "    destination = ' '.join(parts[flight_no_index + 1:to_end_index])\n",
        "\n",
        "    # Append extracted data to the list\n",
        "    data.append([date, flight_no, destination, departure_time, estimated_time])\n",
        "\n",
        "# Define column names\n",
        "columns = ['DATE', 'FLIGHT NO.', 'To', 'DEPARTURE TIME', 'ESTIMATED TIME']\n",
        "\n",
        "# Create a DataFrame\n",
        "df_new = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/Guam')\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file\n",
        "# Sorting at 13:30 pct\n",
        "csv_file_new = os.path.join(downloads_directory, 'Guam_0706_2024.csv')\n",
        "excel_file_new = os.path.join(downloads_directory, 'Guam_0706_2024.xlsx')\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_new.to_csv(csv_file_new, index=False)\n",
        "print(f\"New flight data has been written to {csv_file_new}\")\n",
        "\n",
        "# Save the new DataFrame to an Excel file\n",
        "df_new.to_excel(excel_file_new, index=False)\n",
        "print(f\"New flight data has been written to {excel_file_new}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-qI7yU2PvcZ",
        "outputId": "c3e02f26-a153-46af-bba0-0a2b82de45c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New flight data has been written to /root/Guam/Guam_0706_2024.csv\n",
            "New flight data has been written to /root/Guam/Guam_0706_2024.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do at 10：30 Naha\n"
      ],
      "metadata": {
        "id": "_HUDdPVg11Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://www.naha-airport.co.jp/en/flight/month/?type=depart&type_airport=international&airport=TPE\n",
        "\n",
        "\n",
        "international\n",
        "https://www.naha-airport.co.jp/en/flight/month/?type=depart&type_airport=international&airport=TPE\n",
        "\n"
      ],
      "metadata": {
        "id": "fJgPaX3bxkms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the new raw data\n",
        "new_raw_data = \"\"\"\tMM 923\t08:10\t08:45\n",
        "IT 231\t10:10\t10:40\n",
        "BR 113\t10:15\t10:55\n",
        "CI 121\t11:50\t12:25\n",
        "MM 925\t13:15\t13:50\tDeparture 13:25 Arrival 14:00 on Tuesdays and Fridays\n",
        "JX 871\t15:35\t16:05\n",
        "MM 927\t16:45\t17:20\n",
        "OD 883\t16:50\t17:30\tBound for Kuala Lumpur via Taipei / Operates on Mondays, Wednesdays, Fridays and Sundays\n",
        "FD 231\t16:55\t17:30\tBound for Bangkok via Taipei Departure 17:35 Arrival 18:10 on Sundays\n",
        "BR 185\t19:55\t20:30\n",
        "CI 123\t20:35\t21:10\tOperates on Tuesdays, Thursdays, Saturdays, Sundays\"\"\"\n",
        "\n",
        "# Split the new data into lines\n",
        "lines = new_raw_data.split('\\n')\n",
        "data = []\n",
        "\n",
        "# Extract data from each line\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    flight_no = parts[0] + \" \" + parts[1]\n",
        "    departure_time = parts[2]\n",
        "    arrival_time = parts[3]\n",
        "    remarks = ' '.join(parts[4:]) if len(parts) > 4 else ''\n",
        "\n",
        "    # Append extracted data to the list\n",
        "    data.append([flight_no, departure_time, arrival_time, remarks])\n",
        "\n",
        "# Define column names\n",
        "columns = ['Flight No', 'Departure Time', 'Arrival Time', 'Remarks']\n",
        "\n",
        "# Create a DataFrame\n",
        "df_new = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/Okinawa')\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file\n",
        "csv_file_new = os.path.join(downloads_directory, 'Naha_intern_0705_2024.csv')\n",
        "excel_file_new = os.path.join(downloads_directory, 'Naha_intern_0705_2024.xlsx')\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_new.to_csv(csv_file_new, index=False)\n",
        "print(f\"Filtered flight data with remarks has been written to {csv_file_new}\")\n",
        "\n",
        "# Save the new DataFrame to an Excel file\n",
        "df_new.to_excel(excel_file_new, index=False)\n",
        "print(f\"Filtered flight data with remarks has been written to {excel_file_new}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weOXMm0cx_4m",
        "outputId": "a062ac7d-1e0e-4169-a75a-5cccff0416b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered flight data with remarks has been written to /root/Okinawa/Naha_intern_0705_2024.csv\n",
            "Filtered flight data with remarks has been written to /root/Okinawa/Naha_intern_0705_2024.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**domestic**\n",
        "https://www.naha-airport.co.jp/en/flight/month/?type=depart&type_airport=domestic&airport=CTS\n"
      ],
      "metadata": {
        "id": "7-uf3Hb8zoBt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the new raw data\n",
        "new_raw_data = \"\"\"\tMM 272\t16:10\t19:40\t\"\"\"\n",
        "\n",
        "# Split the new data into lines\n",
        "lines = new_raw_data.split('\\n')\n",
        "data = []\n",
        "\n",
        "# Extract data from each line\n",
        "for line in lines:\n",
        "    parts = line.split()\n",
        "    flight_no = parts[0] + \" \" + parts[1]\n",
        "    departure_time = parts[2]\n",
        "    arrival_time = parts[3]\n",
        "    remarks = ' '.join(parts[4:]) if len(parts) > 4 else ''\n",
        "\n",
        "    # Append extracted data to the list\n",
        "    data.append([flight_no, departure_time, arrival_time, remarks])\n",
        "\n",
        "# Define column names\n",
        "columns = ['Flight No', 'Departure Time', 'Arrival Time', 'Remarks']\n",
        "\n",
        "# Create a DataFrame\n",
        "df_new = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Define the path to the Downloads directory\n",
        "downloads_directory = os.path.expanduser('~/Okinawa')\n",
        "os.makedirs(downloads_directory, exist_ok=True)\n",
        "\n",
        "# Define the full path to the CSV file\n",
        "csv_file_new = os.path.join(downloads_directory, 'Naha_Domestic_0705_2024.csv')\n",
        "excel_file_new = os.path.join(downloads_directory, 'Naha_Domesitc_0705_2024.xlsx')\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_new.to_csv(csv_file_new, index=False)\n",
        "print(f\"Filtered flight data with remarks has been written to {csv_file_new}\")\n",
        "\n",
        "# Save the new DataFrame to an Excel file\n",
        "df_new.to_excel(excel_file_new, index=False)\n",
        "print(f\"Filtered flight data with remarks has been written to {excel_file_new}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJSUWulTzmRP",
        "outputId": "6d02405b-f664-48ce-bde2-5dcc2f435243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered flight data with remarks has been written to /root/Okinawa/Naha_Domestic_0705_2024.csv\n",
            "Filtered flight data with remarks has been written to /root/Okinawa/Naha_Domesitc_0705_2024.xlsx\n"
          ]
        }
      ]
    }
  ]
}